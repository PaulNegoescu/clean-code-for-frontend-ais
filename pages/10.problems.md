---
level: 2
---

# The Problems of AI

1. There is evidence that current AI models including LLMs and Diffusion models are logarithmically tapering in performance and the costs for zero-shot performance would be astronomically high.
<p>

- Computerphile on this: [https://www.youtube.com/watch?v=dDUC-LqVrPU](https://www.youtube.com/watch?v=dDUC-LqVrPU)
- The research paper: [https://arxiv.org/abs/2404.04125](https://arxiv.org/abs/2404.04125)

</p>

2. Training data currently is of questionable quality and this quality gets propagated more by AI
3. Code on the internet is immensely skewed towards old/outdated tech, even if AI has access to current data, most of its input is very old.
4. AI does not understand why it does what it does. It knows how to predict text, but it doesn't understand the big picture, the implications of said text. 

<!-- 
Point 4: This is how some logic errors slip through and sometimes it introduces redundant or useless code. Another example is that Chat GPT did not understand why it used `display: grid` in one instance or what the benefits of doing that were, it still used way too many HTML elements for what it needed.
 -->

---
level: 2
---

# The Problems of AI

5. AI is not capable of understanding business needs and extrapolating a solution, especially if it's a new problem. 

Conclusion: Interviews need new problems expressed in a high level way.

<!-- 
This is why prompts have to be so long and specific.
-->

<p>

[https://interviewing.io/blog/how-hard-is-it-to-cheat-with-chatgpt-in-technical-interviews](https://interviewing.io/blog/how-hard-is-it-to-cheat-with-chatgpt-in-technical-interviews)

</p>

6. AI is not holistic. It seems to currently cherry-pick context (even ignoring that most models don't hold your full project's context) and it's not very good on figuring out on its own what is important in a (new) situation. 

<!-- 
AI can't figure out what's important, what a change might cause in terms of regressions or how it might affect something else. It's especially obvious in other contexts like for example DMing, if asked to pull essential points out of a document it focuses on some but ignores others especially if they are marked differently but are of same importance. It does the same to code, it will ignore bits and focus on sometimes unnecessary stuff and forget about other parts
-->

---
level: 2
---

# The Problems of AI

7. The "average result" problem.

<img src="/average-face.png" alt="average woman face" class="w-160" />

<!-- 
There was this expreriment at one time where they tried to obtain the average face of women by geographic region. This was done by hand and resulted in objectively pretty pictures but which have a certain "sameyness". AI faces similar problems with code as well. The models kind of average their training input and the output is samey and recurrently faces the same issues and lack of creativity.
 -->

---
level: 2
---

# The Problems of AI

8. The Ouroboros AI problem (or: the increasing "entropy" of AI solutions). AI makes itself/each-other worse over time by diluting the training data that is openly available on the internet with sub-par solutions. See the Spotify Recommender Engine in Discover Weekly for a quick and dirty example.

<img src="/ouroboros.png" alt="ai mechanical ouroboros dragon eating its own tail becoming more and more broken down towards the tail end" class="w-80 m-auto" />

<!-- 
I hope all of you know Spotify's recommender engine and you might have better or worse results with it depending on your mileage. But try to listen to Discover Weekly, an automated playlist specifically generated for you every week based on what you listened to recently. You might be surprised to initially find a lot of good new tracks, and you keep listening to it, week after week. Spotify keeps generating the playlist but the only input it gets is its own generated output. After a while Discover Weekly not only does not get you anything good anymore, it becomes subjectively horrible.

AI is currently generating more and more images and code which make it to the web where other AIs or worse, the original one, pick up this work and use it as training input.
 -->
